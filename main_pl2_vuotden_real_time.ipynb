{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "fKrMNdcuru0C"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "id": "jQs-_Wos82fg"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "model = YOLO(\"/content/sample_data/last.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "i7mHGN2XuI1j",
        "outputId": "3e1f7a6d-9e57-4b84-adb9-471ad2219bb9"
      },
      "outputs": [],
      "source": [
        "from paddleocr import PaddleOCR\n",
        "import cv2\n",
        "import re\n",
        "# test_folder = '/kaggle/working/results'\n",
        "test_folder = \"./results\"\n",
        "# !rm -rf ./results\n",
        "# os.mkdir(test_folder)\n",
        "CONFIDENCE_THRESHOLD = 0.5\n",
        "\n",
        "# https://paddlepaddle.github.io/PaddleOCR/latest/en/quick_start.html#use-by-code\n",
        "ocr = PaddleOCR(use_angle_cls = True, use_gpu = True)\n",
        "\n",
        "def paddle_ocr(image, x1, y1, x2, y2):\n",
        "    image = image[max(0, y1-5) : (y2+5), max(0, x1-5) : (x2+5)]\n",
        "    # image = cv2.resize(image, (int(image.shape[1] * 1.1), int(image.shape[0] * 1.1)), interpolation=cv2.INTER_LINEAR)\n",
        "    # gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    # blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "    # sharp = cv2.Laplacian(blurred, cv2.CV_64F)\n",
        "\n",
        "    # thresh = cv2.adaptiveThreshold(sharp, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
        "    result = ocr.ocr(image, det=True, rec = True, cls = False)\n",
        "    if result is None  or result[0] is None:\n",
        "        return\n",
        "    text_score = []\n",
        "    print(result[0])\n",
        "    for line in result[0]:\n",
        "        l_text, scores = line[1][0], line[1][1]\n",
        "        if np.isnan(scores):\n",
        "            scores = 0\n",
        "        else:  # threshold\n",
        "            scores = int(scores * 100)\n",
        "        if 50 < scores:\n",
        "            text_score.append((l_text, scores))\n",
        "    text = \"\".join(t[0] for t in text_score)\n",
        "    score = np.average([int(t[1]) for t in text_score]) if text_score else 0\n",
        "    pattern = re.compile('[\\W]')\n",
        "    text = pattern.sub('', text)\n",
        "    text = text.replace(\"???\", \"\")\n",
        "    text = text.replace(\"O\", \"0\")\n",
        "    text = text.replace(\"粤\", \"\")\n",
        "\n",
        "    # car plate: 7-8 characters\n",
        "    if len(text) < 9:\n",
        "        return text, score\n",
        "\n",
        "def predict_ocr(image):\n",
        "    \"\"\"\n",
        "        image: vehicle image was cropped\n",
        "    \"\"\"\n",
        "    results = model.predict(image, device='cuda')\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    # plt.imshow(image)\n",
        "    if results is None:\n",
        "        return\n",
        "    # process for single vehicle\n",
        "    for result in results:\n",
        "        for box in result.boxes:\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0])    # coordinates of plate\n",
        "            return paddle_ocr(image, x1, y1, x2, y2)\n",
        "\n",
        "    # process for multiple vehicle\n",
        "    # for result in results:\n",
        "    #     filtered_boxes = [box for box in result.boxes if box.conf[0] > CONFIDENCE_THRESHOLD]\n",
        "    #     for box in filtered_boxes:\n",
        "    #         x1, y1, x2, y2 = map(int, box.xyxy[0])    # plate\n",
        "    #         # confidence = box.conf[0]  # Get confidence\n",
        "\n",
        "    #         # Crop bounding box\n",
        "    #         # rect = image[y1:y2, x1:x2]\n",
        "    #         # plt.imshow(rect)\n",
        "    #         # print((x1, y1), (x2, y2))\n",
        "    #         # text = paddle_ocr(image, x1, y1, x2, y2)\n",
        "    #         return paddle_ocr(image, x1, y1, x2, y2)\n",
        "\n",
        "\n",
        "    #         # print(\"NONE\") if result==None else print(result)\n",
        "    #         # text = result[0][0]\n",
        "\n",
        "    #         # print(f\"Detected text: {confidence:.2f}_{text}\")\n",
        "    #         # cv2.putText(image, f'{confidence:.2f}_{text}', (x1-30, y1-10),\n",
        "    #         #         cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)\n",
        "\n",
        "    #         # cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
        "\n",
        "    #         # boxes = [elements[0] for elements in line for line in result]\n",
        "    #         # txts = [elements[1][0] for elements in line for line in result]\n",
        "    #         # scores = [elements[1][1] for elements in line for line in result]\n",
        "    #         # output = draw_ocr(image, boxes, txts, scores, font_path='path_to_font.ttf')\n",
        "\n",
        "    #         # # text = pytesseract.image_to_string(rect, config='--psm 6')  # perform OCR\n",
        "    # return paddle_ocr(image, x1, y1, x2, y2)\n",
        "\n",
        "def predict_folder(path_test):\n",
        "    for img in os.listdir(path_test):\n",
        "        image = cv2.imread(os.path.join(path_test, img))\n",
        "        image = predict_ocr(image)\n",
        "        cv2.imwrite(os.path.join(test_folder, img), image)\n",
        "\n",
        "# predict_folder('/kaggle/input/demo-ttt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dru12tL_wpuG"
      },
      "source": [
        "### check plate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cdq_Ph0FPlnn"
      },
      "outputs": [],
      "source": [
        "list_plate = []\n",
        "def check_backup(time, name_vehicle, plate_number, score, str_vuotdendo):\n",
        "  if len(plate_number) in (6, 7, 8, 9):\n",
        "    list_plate.append((round(time/1000, 2), name_vehicle, plate_number, int(score), str_vuotdendo))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sU0GeeRjwrpc"
      },
      "source": [
        "### vượt đèn đỏ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqm8b1otw_7d"
      },
      "outputs": [],
      "source": [
        "def check_red_light(image):\n",
        "  \"\"\"\n",
        "    traffic light was cropped\n",
        "  \"\"\"\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
        "  lower_red1 = np.array([0, 120, 70])\n",
        "  upper_red1 = np.array([10, 255, 255])\n",
        "  lower_red2 = np.array([170, 120, 70])\n",
        "  upper_red2 = np.array([180, 255, 255])\n",
        "  mask = cv2.inRange(image, lower_red1, upper_red1) + cv2.inRange(image, lower_red2, upper_red2)\n",
        "  red_pixels = cv2.countNonZero(mask)\n",
        "  return True if red_pixels > 500 else False\n",
        "\n",
        "def check_cross_red_light(x2, y2):\n",
        "  if 722 < x2 < 1290 and 420 < y2 < 890:\n",
        "    return True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hGvFXbr0uLga",
        "outputId": "9f642510-5f84-42a7-cbce-fb74cff82c1f"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "# !rm -rf /kaggle/working/vid_results\n",
        "# os.mkdir(\"/kaggle/working/vid_results\")\n",
        "video_path = \"/content/sample_data/test.mp4\"\n",
        "vidcap = cv2.VideoCapture(video_path)\n",
        "\n",
        "model2 = YOLO(\"yolo12n.pt\")\n",
        "CONFIDENCE_THRESHOLD = 0.5\n",
        "\n",
        "vidcap.set(cv2.CAP_PROP_FPS, 60)\n",
        "vidcap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
        "vidcap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
        "\n",
        "fps = int(vidcap.get(cv2.CAP_PROP_FPS))\n",
        "width = int(vidcap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(vidcap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "output_path = './processed_vid.mp4'\n",
        "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "if not vidcap.isOpened():\n",
        "    print(\"Error opening video stream\")\n",
        "    exit()\n",
        "\n",
        "frame_count = 0\n",
        "while True:\n",
        "    success, frame = vidcap.read()\n",
        "    if not success:\n",
        "        break\n",
        "    # if frame_count % 2 == 0:\n",
        "    time_in_ms = vidcap.get(cv2.CAP_PROP_POS_MSEC)\n",
        "    results = model2.predict(frame, device='cuda', classes=[2, 3, 5, 7])\n",
        "    for result in results:\n",
        "        filtered_boxes = [box for box in result.boxes if box.conf[0] > CONFIDENCE_THRESHOLD ]\n",
        "        for box in filtered_boxes:\n",
        "\n",
        "            str_vuotdendo = \"\"\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0])   # (x1, y1), (x2, y2): coordinates of the vehicle\n",
        "            if check_red_light(frame[1290:1335, 210:250]) and check_cross_red_light(x2, y2):\n",
        "                str_vuotdendo = \"vuot den do\"\n",
        "\n",
        "\n",
        "            confidence = box.conf[0]\n",
        "            cls = int(box.cls[0])\n",
        "            list_vehicle = {2: \"car\", 3: \"motorbike\", 5: \"bus\", 7: \"truck\"}\n",
        "            name_vehicle = list_vehicle[cls]\n",
        "            vehicle = frame[max(0, y1-5):y2+5, max(0, x1-5):x2+5]     # crop vehicle\n",
        "            ocr_result = predict_ocr(vehicle)    # text: number plate\n",
        "            text, score = ocr_result if ocr_result is not None else (\"\", 0)\n",
        "            # print(f\"Detected text: {confidence:.2f}_{cls}_{text}\")\n",
        "\n",
        "\n",
        "            if text is not None:\n",
        "                check_backup(time_in_ms, name_vehicle, text, score, str_vuotdendo)\n",
        "                cv2.putText(frame, f'{confidence:.2f}_{name_vehicle}_{text}{str_vuotdendo}', (x1-10, y1-10),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
        "            else:\n",
        "                cv2.putText(frame, f'{confidence:.2f}_{name_vehicle}{str_vuotdendo}', (x1-10, y1-10),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
        "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "    # frame = predict_ocr(frame)\n",
        "    # frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    # cv2.imwrite(f\"./results/frame_{frame_count}.jpg\", frame)\n",
        "    # frame = cv2.resize(frame, (960, 640))\n",
        "    # cv2.imshow(\"Video\", frame)\n",
        "    out.write(frame)\n",
        "    frame_count += 1\n",
        "      # if cv2.waitKey(30) & 0xFF == ord('q'):\n",
        "      #     break\n",
        "\n",
        "vidcap.release()\n",
        "out.release()\n",
        "\n",
        "# cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RuukcHnYNu_",
        "outputId": "e7c6421f-1e0e-40ba-b055-48b0c7d552a4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('car', '30073167', 70),\n",
              " ('car', '307310', 68),\n",
              " ('car', '3071952', 53),\n",
              " ('car', '30473962', 82),\n",
              " ('car', '3073961', 66),\n",
              " ('car', '073952', 88),\n",
              " ('car', '30H73952', 81),\n",
              " ('car', '20473952', 69),\n",
              " ('car', '20N72952', 74),\n",
              " ('car', '30M73957', 73),\n",
              " ('car', '30M73952', 78),\n",
              " ('car', '30W73952', 82),\n",
              " ('car', '30473962', 89),\n",
              " ('car', '30G75720', 98),\n",
              " ('car', '30H73962', 67),\n",
              " ('car', '0G1157', 79),\n",
              " ('car', '30H73962', 91),\n",
              " ('car', '01157元', 81),\n",
              " ('car', '30H73962', 87),\n",
              " ('car', '30H73962', 92),\n",
              " ('car', 'motorl', 89),\n",
              " ('car', '30H73962', 96),\n",
              " ('car', '30H73962', 93),\n",
              " ('truck', '30H73962', 97),\n",
              " ('car', '30H73962', 96),\n",
              " ('car', '30611570', 91),\n",
              " ('car', '30G11570', 97),\n",
              " ('car', '30H73962', 96),\n",
              " ('car', '30H73962', 95),\n",
              " ('car', '30G11570', 97),\n",
              " ('car', '30H73962', 97),\n",
              " ('car', '30G11570', 93),\n",
              " ('car', '30H73962', 96),\n",
              " ('car', '30G11570', 97),\n",
              " ('car', '30H73962', 97),\n",
              " ('car', '30G11570', 98),\n",
              " ('car', '30H73962', 95),\n",
              " ('car', '30G11570', 98),\n",
              " ('car', '30H73962', 95),\n",
              " ('car', '30G11570', 97),\n",
              " ('car', '30H73962', 97),\n",
              " ('car', '30G11570', 98),\n",
              " ('car', '30G11570', 99),\n",
              " ('car', '30G11570', 97),\n",
              " ('car', '081_car_', 95),\n",
              " ('car', '30G11570', 92),\n",
              " ('car', '30G11570', 99),\n",
              " ('car', '30G11570', 99),\n",
              " ('car', '30G11570', 99),\n",
              " ('car', '30G11570', 99),\n",
              " ('car', '30G11570', 98),\n",
              " ('car', '30G11570', 98),\n",
              " ('car', '30G11570', 97),\n",
              " ('car', '30G11570', 96),\n",
              " ('car', '30G11570', 98),\n",
              " ('car', 'TH8039', 99),\n",
              " ('car', 'TH8039', 99),\n",
              " ('car', 'TH8039', 98),\n",
              " ('car', 'TH8039', 99),\n",
              " ('car', 'TH8039', 99),\n",
              " ('car', 'TH8039', 99),\n",
              " ('car', 'TH8039', 98),\n",
              " ('car', 'TH8039', 99),\n",
              " ('car', 'TH8039', 99),\n",
              " ('car', 'TH8039', 99),\n",
              " ('car', 'TH8039', 99),\n",
              " ('car', '1538452', 61),\n",
              " ('car', '29A88664', 98),\n",
              " ('car', '29A88664', 98),\n",
              " ('car', '29A88664', 99),\n",
              " ('car', '29A88664', 98),\n",
              " ('car', '29A88664', 99),\n",
              " ('car', '29A88664', 97),\n",
              " ('car', '29A88664', 99),\n",
              " ('car', '430137', 63),\n",
              " ('car', '154479', 67),\n",
              " ('car', '15441796', 83),\n",
              " ('car', '15441796', 85),\n",
              " ('car', '15441796', 87),\n",
              " ('car', '15441796', 89),\n",
              " ('car', '15441756', 83),\n",
              " ('car', '15441796', 91),\n",
              " ('car', '15A41796', 97),\n",
              " ('car', '15441796', 92),\n",
              " ('car', '15441796', 94),\n",
              " ('car', '15A41795', 92),\n",
              " ('car', '15A41796', 87),\n",
              " ('car', '4813730A', 93),\n",
              " ('car', '15A41796', 94),\n",
              " ('car', '15A41796', 93),\n",
              " ('car', '15A41796', 92),\n",
              " ('car', '15A41796', 98),\n",
              " ('car', '15A41796', 98),\n",
              " ('car', '15A41796', 99),\n",
              " ('car', '15A41796', 96),\n",
              " ('car', '15A41796', 96),\n",
              " ('car', '15A41796', 95),\n",
              " ('car', '15A41796', 94),\n",
              " ('car', '15A41796', 96),\n",
              " ('car', '15A41796', 97),\n",
              " ('car', '15A41796', 96),\n",
              " ('car', '15A41796', 97),\n",
              " ('car', '15A41796', 98),\n",
              " ('car', '15A41796', 99),\n",
              " ('car', 'aotort', 85),\n",
              " ('car', '30HB0368', 83),\n",
              " ('car', '30H80368', 92),\n",
              " ('car', '30H80368', 93),\n",
              " ('car', '30H80368', 97),\n",
              " ('car', '30H80368', 96),\n",
              " ('car', '30H80368', 94),\n",
              " ('car', '30H80368', 96),\n",
              " ('car', '30H80368', 96),\n",
              " ('car', '30HB0368', 90)]"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list_plate\n",
        "# vehicles_id"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
